{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6fafe1b-01d3-4f3c-9440-7df4d324e461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AS faiss wasnt working for me i decided to use chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9056fb6f-5f74-465a-b575-b743fb52e58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "# Set GPU device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07578b83-ae02-43ea-a72a-f945eb5aa590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "# Original prompt template\n",
    "prompt_template = \"\"\"\n",
    "    This is a chatbot designed to answer questions about Aymen. \n",
    "    It Uses the provided documents to answer questions accurately and politely.\"\n",
    "    {context}\n",
    "    Question: {question}\n",
    "    Answer:\n",
    "    \"\"\".strip()\n",
    "\n",
    "PROMPT = PromptTemplate.from_template(template=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a602816-f5ce-4468-8b41-e68e4f3564f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a chatbot designed to answer questions about Aymen. \n",
      "    It Uses the provided documents to answer questions accurately and politely.\"\n",
      "    \n",
      "Aymen is a Master's student in DSAI at AIT. \n",
      "They graduated with a bachelors degree in Electrical Engineering.\n",
      "\n",
      "    Question: What is Aymen's highest level of education?\n",
      "    Answer:\n"
     ]
    }
   ],
   "source": [
    "# Define the context and question\n",
    "context = \"\"\"\n",
    "Aymen is a Master's student in DSAI at AIT. \n",
    "They graduated with a bachelors degree in Electrical Engineering.\n",
    "\"\"\"\n",
    "question = \"What is Aymen's highest level of education?\"\n",
    "\n",
    "# Format the prompt\n",
    "formatted_prompt = PROMPT.format(context=context, question=question)\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebf3dacd-b1c5-4636-94fe-20a7f9c3ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the txt documents that include my information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba6008dd-5326-4640-8e63-b707da9fa665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# Load education document\n",
    "education_loader = TextLoader('education.txt')\n",
    "education = education_loader.load()\n",
    "\n",
    "# Load beliefs document\n",
    "beliefs_loader = TextLoader('beliefs.txt')\n",
    "beliefs = beliefs_loader.load()\n",
    "\n",
    "# Load academics document\n",
    "academics_loader = TextLoader('academics.txt')\n",
    "academics = academics_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "523e3472-6be0-4a7a-8cae-d0a283730355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents loaded: 3\n",
      "Education and Background\n",
      "\n",
      "Personal Information:\n",
      "- Name: Aymen Zubair Qureshi\n",
      "- Date of Birth: August 15, 2002\n",
      "- Age: 22\n",
      "\n",
      "Education:\n",
      "1. Master of Science in Data Science and Artificial Intelligence:\n",
      "   - Institution: Asian Institute of Technology, Thailand\n",
      "   - Duration: August 2024 – Present\n",
      "   - Focus Areas: Machine Learning, Deep Learning, AI Ethics\n",
      "\n",
      "2. Bachelor of Science in Electrical Engineering (Communication Major):\n",
      "   - Institution: University of Engineering and Technology (UET), Pakistan\n",
      "   - Duration: 2020–2024\n",
      "   - Focus Areas: Signal Processing, Communication Systems\n",
      "\n",
      "Highest Level of Education: Master’s Degree\n",
      "Field of Study: Data Science and Artificial Intelligence\n"
     ]
    }
   ],
   "source": [
    "# Combine all documents into a single list\n",
    "documents = education + beliefs + academics\n",
    "\n",
    "# Check the number of documents loaded\n",
    "print(f\"Number of documents loaded: {len(documents)}\")\n",
    "\n",
    "# Inspect the first document (optional)\n",
    "print(documents[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ace962b5-5905-49a8-b0c3-d5f9c1f2e034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 6\n",
      "Education and Background\n",
      "\n",
      "Personal Information:\n",
      "- Name: Aymen Zubair Qureshi\n",
      "- Date of Birth: August 15, 2002\n",
      "- Age: 22\n",
      "\n",
      "Education:\n",
      "1. Master of Science in Data Science and Artificial Intelligence:\n",
      "   - Institution: Asian Institute of Technology, Thailand\n",
      "   - Duration: August 2024 – Present\n",
      "   - Focus Areas: Machine Learning, Deep Learning, AI Ethics\n",
      "\n",
      "2. Bachelor of Science in Electrical Engineering (Communication Major):\n",
      "   - Institution: University of Engineering and Technology (UET), Pakistan\n",
      "   - Duration: 2020–2024\n",
      "   - Focus Areas: Signal Processing, Communication Systems\n",
      "\n",
      "Highest Level of Education: Master’s Degree\n",
      "Field of Study: Data Science and Artificial Intelligence\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Define the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=700,  # Size of each chunk (in characters)\n",
    "    chunk_overlap=100  # Overlap between chunks (in characters)\n",
    ")\n",
    "\n",
    "# Split the documents\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Check the number of chunks\n",
    "print(f\"Number of chunks: {len(docs)}\")\n",
    "\n",
    "# Inspect the first chunk (optional)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67f26bce-1ecd-41f9-b879-907f94c5dc11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'beliefs.txt'}, page_content='Personal Beliefs and Cultural Perspectives\\n\\nCore Beliefs about Technology:\\nI believe that technology has the power to transform societies by improving access to education, healthcare, and economic opportunities. However, it is crucial to ensure that technological advancements are inclusive and ethical, addressing the needs of all communities, especially marginalized ones.')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "221a289d-781b-485a-84e6-0c2f8365801e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81755/438159016.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Initialize the embedding model\n",
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs={\"device\": device}\n",
    ")\n",
    "\n",
    "print(\"Embedding model initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e456b1ca-6616-4917-ab63-7100628909a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Define the path to save the vector store\n",
    "vector_path = '../vector-store'\n",
    "if not os.path.exists(vector_path):\n",
    "    os.makedirs(vector_path)\n",
    "    print('Created vector store directory.')\n",
    "\n",
    "# Create the Chroma vector store from documents\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=docs,  # Your text chunks\n",
    "    embedding=embedding_model,  # Your embedding model\n",
    "    persist_directory=os.path.join(vector_path, 'chroma_db')  # Save to disk\n",
    ")\n",
    "\n",
    "print(\"Vector store created and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66c2a80c-b35e-45e2-8e9a-54875ee0832b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81755/616098682.py:7: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Define the path to the saved vector store\n",
    "vector_path = '../vector-store'\n",
    "\n",
    "# Load the Chroma vector store\n",
    "vectordb = Chroma(\n",
    "    persist_directory=os.path.join(vector_path, 'chroma_db'),\n",
    "    embedding_function=embedding_model  # Your embedding model\n",
    ")\n",
    "\n",
    "print(\"Vector store loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "154ff30f-b146-4d0e-8bde-6c6cfa246a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant documents for query: 'What is Aymens education level?'\n",
      "Education and Background\n",
      "\n",
      "Personal Information:\n",
      "- Name: Aymen Zubair Qureshi\n",
      "- Date of Birth: August 15, 2002\n",
      "- Age: 22\n",
      "\n",
      "Education:\n",
      "1. Master of Science in Data Science and Artificial Intelligence:\n",
      "   - Institution: Asian Institute of Technology, Thailand\n",
      "   - Duration: August 2024 – Present\n",
      "   - Focus Areas: Machine Learning, Deep Learning, AI Ethics\n",
      "\n",
      "2. Bachelor of Science in Electrical Engineering (Communication Major):\n",
      "   - Institution: University of Engineering and Technology (UET), Pakistan\n",
      "   - Duration: 2020–2024\n",
      "   - Focus Areas: Signal Processing, Communication Systems\n",
      "\n",
      "Highest Level of Education: Master’s Degree\n",
      "Field of Study: Data Science and Artificial Intelligence\n",
      "Education and Background\n",
      "\n",
      "Personal Information:\n",
      "- Name: Aymen Zubair Qureshi\n",
      "- Date of Birth: August 15, 2002\n",
      "- Age: 22\n",
      "\n",
      "Education:\n",
      "1. Master of Science in Data Science and Artificial Intelligence:\n",
      "   - Institution: Asian Institute of Technology, Thailand\n",
      "   - Duration: August 2024 – Present\n",
      "   - Focus Areas: Machine Learning, Deep Learning, AI Ethics\n",
      "\n",
      "2. Bachelor of Science in Electrical Engineering (Communication Major):\n",
      "   - Institution: University of Engineering and Technology (UET), Pakistan\n",
      "   - Duration: 2020–2024\n",
      "   - Focus Areas: Signal Processing, Communication Systems\n",
      "\n",
      "Highest Level of Education: Master’s Degree\n",
      "Field of Study: Data Science and Artificial Intelligence\n",
      "Education and Background\n",
      "\n",
      "Personal Information:\n",
      "- Name: Aymen Zubair Qureshi\n",
      "- Date of Birth: August 15, 2002\n",
      "- Age: 22\n",
      "\n",
      "Education:\n",
      "1. Master of Science in Data Science and Artificial Intelligence:\n",
      "   - Institution: Asian Institute of Technology, Thailand\n",
      "   - Duration: August 2024 – Present\n",
      "   - Focus Areas: Machine Learning, Deep Learning, AI Ethics\n",
      "\n",
      "2. Bachelor of Science in Electrical Engineering (Communication Major):\n",
      "   - Institution: University of Engineering and Technology (UET), Pakistan\n",
      "   - Duration: 2020–2024\n",
      "   - Focus Areas: Signal Processing, Communication Systems\n",
      "\n",
      "Highest Level of Education: Master’s Degree\n",
      "Field of Study: Data Science and Artificial Intelligence\n",
      "Education and Background\n",
      "\n",
      "Personal Information:\n",
      "- Name: Aymen Zubair Qureshi\n",
      "- Date of Birth: August 15, 2002\n",
      "- Age: 22\n",
      "\n",
      "Education:\n",
      "1. Master of Science in Data Science and Artificial Intelligence:\n",
      "   - Institution: Asian Institute of Technology, Thailand\n",
      "   - Duration: August 2024 – Present\n",
      "   - Focus Areas: Machine Learning, Deep Learning, AI Ethics\n",
      "\n",
      "2. Bachelor of Science in Electrical Engineering (Communication Major):\n",
      "   - Institution: University of Engineering and Technology (UET), Pakistan\n",
      "   - Duration: 2020–2024\n",
      "   - Focus Areas: Signal Processing, Communication Systems\n",
      "\n",
      "Highest Level of Education: Master’s Degree\n",
      "Field of Study: Data Science and Artificial Intelligence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81755/1207648260.py:6: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  relevant_docs = retriever.get_relevant_documents(query)\n"
     ]
    }
   ],
   "source": [
    "# Create a retriever\n",
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "# Test the retriever\n",
    "query = \"What is Aymens education level?\"\n",
    "relevant_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Relevant documents for query: '{query}'\")\n",
    "for doc in relevant_docs:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84bb2e86-a642-400d-a4c5-db93ed62f1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat History:\n",
      "human: hi\n",
      "ai: What's up?\n",
      "human: How are you?\n",
      "ai: I'm quite good. How about you?\n",
      "\n",
      "Memory Buffer:\n",
      "{'history': \"Human: hi\\nAI: What's up?\\nHuman: How are you?\\nAI: I'm quite good. How about you?\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81755/3977671842.py:20: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ChatMessageHistory, ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Step 1: Initialize memory\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "# Add user and AI messages\n",
    "history.add_user_message(\"hi\")\n",
    "history.add_ai_message(\"What's up?\")\n",
    "history.add_user_message(\"How are you?\")\n",
    "history.add_ai_message(\"I'm quite good. How about you?\")\n",
    "\n",
    "# Print the conversation history\n",
    "print(\"Chat History:\")\n",
    "for message in history.messages:\n",
    "    print(f\"{message.type}: {message.content}\")\n",
    "\n",
    "# Step 2: Use ConversationBufferMemory\n",
    "memory = ConversationBufferMemory()\n",
    "memory.save_context({\"input\": \"hi\"}, {\"output\": \"What's up?\"})\n",
    "memory.save_context({\"input\": \"How are you?\"}, {\"output\": \"I'm quite good. How about you?\"})\n",
    "\n",
    "# Print the memory buffer\n",
    "print(\"\\nMemory Buffer:\")\n",
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9847993d-5dee-473a-9be5-f9a592323175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b81dfd35409b4ab2b7690f827f29e9bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58d621a54804b19bb60e37a150c136b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be77295785542bfb4382408e31ef60d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b578661829463e8b1bcdbe225b940c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673671e120b148109da0664c425a0bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09336adb446847a2b647939233a313b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063c65a91abe468496103982123f7694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: {'input_ids': tensor([[ 363,   19,   71,   63,  904,   31,    7, 1246,   58,    1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output: 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81755/1208319972.py:32: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=pipe)\n",
      "/tmp/ipykernel_81755/1208319972.py:36: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = llm(\"What is Aymen's age?\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain Output: 66\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from langchain import HuggingFacePipeline\n",
    "import re\n",
    "\n",
    "# Step 1: Load the tokenizer and model\n",
    "model_id = \"google/flan-t5-large\"  # Use Flan-T5 instead of fastchat-t5\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "\n",
    "# Step 2: Test the tokenizer and model\n",
    "text = \"What is Aymen's age?\"\n",
    "tokens = tokenizer(text, return_tensors=\"pt\")\n",
    "print(f\"Tokens: {tokens}\")\n",
    "\n",
    "output = model.generate(tokens[\"input_ids\"], max_new_tokens=50)\n",
    "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(f\"Model Output: {decoded_output}\")\n",
    "\n",
    "# Step 3: Create a text generation pipeline\n",
    "pipe = pipeline(\n",
    "    task=\"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=256,\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0,\n",
    "        \"repetition_penalty\": 1.5\n",
    "    }\n",
    ")\n",
    "\n",
    "# Step 4: Wrap the pipeline in a LangChain HuggingFacePipeline\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# Step 5: Test the LangChain pipeline\n",
    "try:\n",
    "    response = llm(\"What is Aymen's age?\")\n",
    "    print(f\"LangChain Output: {response}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in LangChain pipeline: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cda3ac99-492d-4593-8cc3-d0ebed508fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
    "\n",
    "# Define the question generator\n",
    "question_generator = LLMChain(\n",
    "    llm=llm,  # Your language model\n",
    "    prompt=CONDENSE_QUESTION_PROMPT,  # Prompt to rephrase follow-up questions\n",
    "    verbose=True  # For debugging\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "201c8a78-d8ee-482c-bde3-e57cc25d278d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81755/517678038.py:4: LangChainDeprecationWarning: This class is deprecated. See the following migration guides for replacements based on `chain_type`:\n",
      "stuff: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain\n",
      "map_reduce: https://python.langchain.com/docs/versions/migrating_chains/map_reduce_chain\n",
      "refine: https://python.langchain.com/docs/versions/migrating_chains/refine_chain\n",
      "map_rerank: https://python.langchain.com/docs/versions/migrating_chains/map_rerank_docs_chain\n",
      "\n",
      "See also guides on retrieval and question-answering here: https://python.langchain.com/docs/how_to/#qa-with-rag\n",
      "  doc_chain = load_qa_chain(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "# Define the document chain\n",
    "doc_chain = load_qa_chain(\n",
    "    llm=llm,  \n",
    "    chain_type=\"stuff\",  \n",
    "    verbose=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c775c340-e6a8-4495-b5cb-8f38ca49dfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: \n",
      "Aymen is a Master's student in DSAI at AIT. \n",
      "They graduated with a bachelors degree in Electrical Engineering.\n",
      "\n",
      "Question: What is Aymen's highest level of education?\n"
     ]
    }
   ],
   "source": [
    "print(f\"Context: {context}\")\n",
    "print(f\"Question: {question}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79bf1416-1b55-4027-b934-008b0291d7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StuffDocumentsChain(verbose=True, llm_chain=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\"), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text2text_generation.Text2TextGenerationPipeline object at 0x79ffe31e4890>), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_variable_name='context')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cb135a8-5660-4db6-a6b3-900c29a86f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81755/75795424.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(\n",
      "/tmp/ipykernel_81755/75795424.py:10: LangChainDeprecationWarning: The class `ConversationalRetrievalChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~create_history_aware_retriever together with create_retrieval_chain (see example in docstring)` instead.\n",
      "  chain = ConversationalRetrievalChain(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConversationalRetrievalChain(memory=ConversationBufferWindowMemory(chat_memory=InMemoryChatMessageHistory(messages=[]), output_key='answer', return_messages=True, memory_key='chat_history', k=3), verbose=True, combine_docs_chain=StuffDocumentsChain(verbose=True, llm_chain=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\"), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text2text_generation.Text2TextGenerationPipeline object at 0x79ffe31e4890>), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_variable_name='context'), question_generator=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['chat_history', 'question'], input_types={}, partial_variables={}, template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:'), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text2text_generation.Text2TextGenerationPipeline object at 0x79ffe31e4890>), output_parser=StrOutputParser(), llm_kwargs={}), return_source_documents=True, get_chat_history=<function <lambda> at 0x79ffe4d6a480>, retriever=VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x79ffe4d658b0>, search_kwargs={}))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    k=3, \n",
    "    memory_key = \"chat_history\",\n",
    "    return_messages = True,\n",
    "    output_key = 'answer'\n",
    ")\n",
    "\n",
    "chain = ConversationalRetrievalChain(\n",
    "    retriever=retriever,\n",
    "    question_generator=question_generator,\n",
    "    combine_docs_chain=doc_chain,\n",
    "    return_source_documents=True,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    get_chat_history=lambda h: h\n",
    ")\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "594f7b2b-3e20-4588-ba23-c9587f031b57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81755/4270988876.py:2: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  answer = chain({\"question\":prompt_question})\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Education and Background\n",
      "\n",
      "Personal Information:\n",
      "- Name: Aymen Zubair Qureshi\n",
      "- Date of Birth: August 15, 2002\n",
      "- Age: 22\n",
      "\n",
      "Education:\n",
      "1. Master of Science in Data Science and Artificial Intelligence:\n",
      "   - Institution: Asian Institute of Technology, Thailand\n",
      "   - Duration: August 2024 – Present\n",
      "   - Focus Areas: Machine Learning, Deep Learning, AI Ethics\n",
      "\n",
      "2. Bachelor of Science in Electrical Engineering (Communication Major):\n",
      "   - Institution: University of Engineering and Technology (UET), Pakistan\n",
      "   - Duration: 2020–2024\n",
      "   - Focus Areas: Signal Processing, Communication Systems\n",
      "\n",
      "Highest Level of Education: Master’s Degree\n",
      "Field of Study: Data Science and Artificial Intelligence\n",
      "\n",
      "Education and Background\n",
      "\n",
      "Personal Information:\n",
      "- Name: Aymen Zubair Qureshi\n",
      "- Date of Birth: August 15, 2002\n",
      "- Age: 22\n",
      "\n",
      "Education:\n",
      "1. Master of Science in Data Science and Artificial Intelligence:\n",
      "   - Institution: Asian Institute of Technology, Thailand\n",
      "   - Duration: August 2024 – Present\n",
      "   - Focus Areas: Machine Learning, Deep Learning, AI Ethics\n",
      "\n",
      "2. Bachelor of Science in Electrical Engineering (Communication Major):\n",
      "   - Institution: University of Engineering and Technology (UET), Pakistan\n",
      "   - Duration: 2020–2024\n",
      "   - Focus Areas: Signal Processing, Communication Systems\n",
      "\n",
      "Highest Level of Education: Master’s Degree\n",
      "Field of Study: Data Science and Artificial Intelligence\n",
      "\n",
      "Education and Background\n",
      "\n",
      "Personal Information:\n",
      "- Name: Aymen Zubair Qureshi\n",
      "- Date of Birth: August 15, 2002\n",
      "- Age: 22\n",
      "\n",
      "Education:\n",
      "1. Master of Science in Data Science and Artificial Intelligence:\n",
      "   - Institution: Asian Institute of Technology, Thailand\n",
      "   - Duration: August 2024 – Present\n",
      "   - Focus Areas: Machine Learning, Deep Learning, AI Ethics\n",
      "\n",
      "2. Bachelor of Science in Electrical Engineering (Communication Major):\n",
      "   - Institution: University of Engineering and Technology (UET), Pakistan\n",
      "   - Duration: 2020–2024\n",
      "   - Focus Areas: Signal Processing, Communication Systems\n",
      "\n",
      "Highest Level of Education: Master’s Degree\n",
      "Field of Study: Data Science and Artificial Intelligence\n",
      "\n",
      "Education and Background\n",
      "\n",
      "Personal Information:\n",
      "- Name: Aymen Zubair Qureshi\n",
      "- Date of Birth: August 15, 2002\n",
      "- Age: 22\n",
      "\n",
      "Education:\n",
      "1. Master of Science in Data Science and Artificial Intelligence:\n",
      "   - Institution: Asian Institute of Technology, Thailand\n",
      "   - Duration: August 2024 – Present\n",
      "   - Focus Areas: Machine Learning, Deep Learning, AI Ethics\n",
      "\n",
      "2. Bachelor of Science in Electrical Engineering (Communication Major):\n",
      "   - Institution: University of Engineering and Technology (UET), Pakistan\n",
      "   - Duration: 2020–2024\n",
      "   - Focus Areas: Signal Processing, Communication Systems\n",
      "\n",
      "Highest Level of Education: Master’s Degree\n",
      "Field of Study: Data Science and Artificial Intelligence\n",
      "\n",
      "Question:  What is aymens age?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': ' What is aymens age?',\n",
       " 'chat_history': [],\n",
       " 'answer': '22',\n",
       " 'source_documents': [Document(metadata={'source': 'education.txt'}, page_content='Education and Background\\n\\nPersonal Information:\\n- Name: Aymen Zubair Qureshi\\n- Date of Birth: August 15, 2002\\n- Age: 22\\n\\nEducation:\\n1. Master of Science in Data Science and Artificial Intelligence:\\n   - Institution: Asian Institute of Technology, Thailand\\n   - Duration: August 2024 – Present\\n   - Focus Areas: Machine Learning, Deep Learning, AI Ethics\\n\\n2. Bachelor of Science in Electrical Engineering (Communication Major):\\n   - Institution: University of Engineering and Technology (UET), Pakistan\\n   - Duration: 2020–2024\\n   - Focus Areas: Signal Processing, Communication Systems\\n\\nHighest Level of Education: Master’s Degree\\nField of Study: Data Science and Artificial Intelligence'),\n",
       "  Document(metadata={'source': 'education.txt'}, page_content='Education and Background\\n\\nPersonal Information:\\n- Name: Aymen Zubair Qureshi\\n- Date of Birth: August 15, 2002\\n- Age: 22\\n\\nEducation:\\n1. Master of Science in Data Science and Artificial Intelligence:\\n   - Institution: Asian Institute of Technology, Thailand\\n   - Duration: August 2024 – Present\\n   - Focus Areas: Machine Learning, Deep Learning, AI Ethics\\n\\n2. Bachelor of Science in Electrical Engineering (Communication Major):\\n   - Institution: University of Engineering and Technology (UET), Pakistan\\n   - Duration: 2020–2024\\n   - Focus Areas: Signal Processing, Communication Systems\\n\\nHighest Level of Education: Master’s Degree\\nField of Study: Data Science and Artificial Intelligence'),\n",
       "  Document(metadata={'source': 'education.txt'}, page_content='Education and Background\\n\\nPersonal Information:\\n- Name: Aymen Zubair Qureshi\\n- Date of Birth: August 15, 2002\\n- Age: 22\\n\\nEducation:\\n1. Master of Science in Data Science and Artificial Intelligence:\\n   - Institution: Asian Institute of Technology, Thailand\\n   - Duration: August 2024 – Present\\n   - Focus Areas: Machine Learning, Deep Learning, AI Ethics\\n\\n2. Bachelor of Science in Electrical Engineering (Communication Major):\\n   - Institution: University of Engineering and Technology (UET), Pakistan\\n   - Duration: 2020–2024\\n   - Focus Areas: Signal Processing, Communication Systems\\n\\nHighest Level of Education: Master’s Degree\\nField of Study: Data Science and Artificial Intelligence'),\n",
       "  Document(metadata={'source': 'education.txt'}, page_content='Education and Background\\n\\nPersonal Information:\\n- Name: Aymen Zubair Qureshi\\n- Date of Birth: August 15, 2002\\n- Age: 22\\n\\nEducation:\\n1. Master of Science in Data Science and Artificial Intelligence:\\n   - Institution: Asian Institute of Technology, Thailand\\n   - Duration: August 2024 – Present\\n   - Focus Areas: Machine Learning, Deep Learning, AI Ethics\\n\\n2. Bachelor of Science in Electrical Engineering (Communication Major):\\n   - Institution: University of Engineering and Technology (UET), Pakistan\\n   - Duration: 2020–2024\\n   - Focus Areas: Signal Processing, Communication Systems\\n\\nHighest Level of Education: Master’s Degree\\nField of Study: Data Science and Artificial Intelligence')]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_question = \" What is aymens age?\"\n",
    "answer = chain({\"question\":prompt_question})\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09c332f8-fd14-4e7f-a73b-eeff806e50fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "[HumanMessage(content=' What is aymens age?', additional_kwargs={}, response_metadata={}), AIMessage(content='22', additional_kwargs={}, response_metadata={})]\n",
      "Follow Up Input: How old are you?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Education and Background\n",
      "\n",
      "Personal Information:\n",
      "- Name: Aymen Zubair Qureshi\n",
      "- Date of Birth: August 15, 2002\n",
      "- Age: 22\n",
      "\n",
      "Education:\n",
      "1. Master of Science in Data Science and Artificial Intelligence:\n",
      "   - Institution: Asian Institute of Technology, Thailand\n",
      "   - Duration: August 2024 – Present\n",
      "   - Focus Areas: Machine Learning, Deep Learning, AI Ethics\n",
      "\n",
      "2. Bachelor of Science in Electrical Engineering (Communication Major):\n",
      "   - Institution: University of Engineering and Technology (UET), Pakistan\n",
      "   - Duration: 2020–2024\n",
      "   - Focus Areas: Signal Processing, Communication Systems\n",
      "\n",
      "Highest Level of Education: Master’s Degree\n",
      "Field of Study: Data Science and Artificial Intelligence\n",
      "\n",
      "Education and Background\n",
      "\n",
      "Personal Information:\n",
      "- Name: Aymen Zubair Qureshi\n",
      "- Date of Birth: August 15, 2002\n",
      "- Age: 22\n",
      "\n",
      "Education:\n",
      "1. Master of Science in Data Science and Artificial Intelligence:\n",
      "   - Institution: Asian Institute of Technology, Thailand\n",
      "   - Duration: August 2024 – Present\n",
      "   - Focus Areas: Machine Learning, Deep Learning, AI Ethics\n",
      "\n",
      "2. Bachelor of Science in Electrical Engineering (Communication Major):\n",
      "   - Institution: University of Engineering and Technology (UET), Pakistan\n",
      "   - Duration: 2020–2024\n",
      "   - Focus Areas: Signal Processing, Communication Systems\n",
      "\n",
      "Highest Level of Education: Master’s Degree\n",
      "Field of Study: Data Science and Artificial Intelligence\n",
      "\n",
      "Education and Background\n",
      "\n",
      "Personal Information:\n",
      "- Name: Aymen Zubair Qureshi\n",
      "- Date of Birth: August 15, 2002\n",
      "- Age: 22\n",
      "\n",
      "Education:\n",
      "1. Master of Science in Data Science and Artificial Intelligence:\n",
      "   - Institution: Asian Institute of Technology, Thailand\n",
      "   - Duration: August 2024 – Present\n",
      "   - Focus Areas: Machine Learning, Deep Learning, AI Ethics\n",
      "\n",
      "2. Bachelor of Science in Electrical Engineering (Communication Major):\n",
      "   - Institution: University of Engineering and Technology (UET), Pakistan\n",
      "   - Duration: 2020–2024\n",
      "   - Focus Areas: Signal Processing, Communication Systems\n",
      "\n",
      "Highest Level of Education: Master’s Degree\n",
      "Field of Study: Data Science and Artificial Intelligence\n",
      "\n",
      "Education and Background\n",
      "\n",
      "Personal Information:\n",
      "- Name: Aymen Zubair Qureshi\n",
      "- Date of Birth: August 15, 2002\n",
      "- Age: 22\n",
      "\n",
      "Education:\n",
      "1. Master of Science in Data Science and Artificial Intelligence:\n",
      "   - Institution: Asian Institute of Technology, Thailand\n",
      "   - Duration: August 2024 – Present\n",
      "   - Focus Areas: Machine Learning, Deep Learning, AI Ethics\n",
      "\n",
      "2. Bachelor of Science in Electrical Engineering (Communication Major):\n",
      "   - Institution: University of Engineering and Technology (UET), Pakistan\n",
      "   - Duration: 2020–2024\n",
      "   - Focus Areas: Signal Processing, Communication Systems\n",
      "\n",
      "Highest Level of Education: Master’s Degree\n",
      "Field of Study: Data Science and Artificial Intelligence\n",
      "\n",
      "Question: How old are you?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "[HumanMessage(content=' What is aymens age?', additional_kwargs={}, response_metadata={}), AIMessage(content='22', additional_kwargs={}, response_metadata={}), HumanMessage(content='How old are you?', additional_kwargs={}, response_metadata={}), AIMessage(content='22', additional_kwargs={}, response_metadata={})]\n",
      "Follow Up Input: What is your highest level of education?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Education and Background\n",
      "\n",
      "Personal Information:\n",
      "- Name: Aymen Zubair Qureshi\n",
      "- Date of Birth: August 15, 2002\n",
      "- Age: 22\n",
      "\n",
      "Education:\n",
      "1. Master of Science in Data Science and Artificial Intelligence:\n",
      "   - Institution: Asian Institute of Technology, Thailand\n",
      "   - Duration: August 2024 – Present\n",
      "   - Focus Areas: Machine Learning, Deep Learning, AI Ethics\n",
      "\n",
      "2. Bachelor of Science in Electrical Engineering (Communication Major):\n",
      "   - Institution: University of Engineering and Technology (UET), Pakistan\n",
      "   - Duration: 2020–2024\n",
      "   - Focus Areas: Signal Processing, Communication Systems\n",
      "\n",
      "Highest Level of Education: Master’s Degree\n",
      "Field of Study: Data Science and Artificial Intelligence\n",
      "\n",
      "Education and Background\n",
      "\n",
      "Personal Information:\n",
      "- Name: Aymen Zubair Qureshi\n",
      "- Date of Birth: August 15, 2002\n",
      "- Age: 22\n",
      "\n",
      "Education:\n",
      "1. Master of Science in Data Science and Artificial Intelligence:\n",
      "   - Institution: Asian Institute of Technology, Thailand\n",
      "   - Duration: August 2024 – Present\n",
      "   - Focus Areas: Machine Learning, Deep Learning, AI Ethics\n",
      "\n",
      "2. Bachelor of Science in Electrical Engineering (Communication Major):\n",
      "   - Institution: University of Engineering and Technology (UET), Pakistan\n",
      "   - Duration: 2020–2024\n",
      "   - Focus Areas: Signal Processing, Communication Systems\n",
      "\n",
      "Highest Level of Education: Master’s Degree\n",
      "Field of Study: Data Science and Artificial Intelligence\n",
      "\n",
      "Education and Background\n",
      "\n",
      "Personal Information:\n",
      "- Name: Aymen Zubair Qureshi\n",
      "- Date of Birth: August 15, 2002\n",
      "- Age: 22\n",
      "\n",
      "Education:\n",
      "1. Master of Science in Data Science and Artificial Intelligence:\n",
      "   - Institution: Asian Institute of Technology, Thailand\n",
      "   - Duration: August 2024 – Present\n",
      "   - Focus Areas: Machine Learning, Deep Learning, AI Ethics\n",
      "\n",
      "2. Bachelor of Science in Electrical Engineering (Communication Major):\n",
      "   - Institution: University of Engineering and Technology (UET), Pakistan\n",
      "   - Duration: 2020–2024\n",
      "   - Focus Areas: Signal Processing, Communication Systems\n",
      "\n",
      "Highest Level of Education: Master’s Degree\n",
      "Field of Study: Data Science and Artificial Intelligence\n",
      "\n",
      "Education and Background\n",
      "\n",
      "Personal Information:\n",
      "- Name: Aymen Zubair Qureshi\n",
      "- Date of Birth: August 15, 2002\n",
      "- Age: 22\n",
      "\n",
      "Education:\n",
      "1. Master of Science in Data Science and Artificial Intelligence:\n",
      "   - Institution: Asian Institute of Technology, Thailand\n",
      "   - Duration: August 2024 – Present\n",
      "   - Focus Areas: Machine Learning, Deep Learning, AI Ethics\n",
      "\n",
      "2. Bachelor of Science in Electrical Engineering (Communication Major):\n",
      "   - Institution: University of Engineering and Technology (UET), Pakistan\n",
      "   - Duration: 2020–2024\n",
      "   - Focus Areas: Signal Processing, Communication Systems\n",
      "\n",
      "Highest Level of Education: Master’s Degree\n",
      "Field of Study: Data Science and Artificial Intelligence\n",
      "\n",
      "Question: What is your highest level of education?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "[HumanMessage(content=' What is aymens age?', additional_kwargs={}, response_metadata={}), AIMessage(content='22', additional_kwargs={}, response_metadata={}), HumanMessage(content='How old are you?', additional_kwargs={}, response_metadata={}), AIMessage(content='22', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is your highest level of education?', additional_kwargs={}, response_metadata={}), AIMessage(content='Master’s Degree', additional_kwargs={}, response_metadata={})]\n",
      "Follow Up Input: What major or field of study did you pursue during your education?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Academic Challenges and Research Interests\n",
      "\n",
      "Work Experience:\n",
      "- I am currently a student and do not have any formal work experience. However, I have gained practical skills through academic projects and internships.\n",
      "\n",
      "Academic Challenges:\n",
      "The most challenging aspect of my studies so far has been balancing coursework with research. The fast-paced nature of data science and AI requires constant learning and adaptation, which can be overwhelming at times. However, I view this as an opportunity to grow and develop resilience.\n",
      "\n",
      "Academic Challenges and Research Interests\n",
      "\n",
      "Work Experience:\n",
      "- I am currently a student and do not have any formal work experience. However, I have gained practical skills through academic projects and internships.\n",
      "\n",
      "Academic Challenges:\n",
      "The most challenging aspect of my studies so far has been balancing coursework with research. The fast-paced nature of data science and AI requires constant learning and adaptation, which can be overwhelming at times. However, I view this as an opportunity to grow and develop resilience.\n",
      "\n",
      "Academic Challenges and Research Interests\n",
      "\n",
      "Work Experience:\n",
      "- I am currently a student and do not have any formal work experience. However, I have gained practical skills through academic projects and internships.\n",
      "\n",
      "Academic Challenges:\n",
      "The most challenging aspect of my studies so far has been balancing coursework with research. The fast-paced nature of data science and AI requires constant learning and adaptation, which can be overwhelming at times. However, I view this as an opportunity to grow and develop resilience.\n",
      "\n",
      "Academic Challenges and Research Interests\n",
      "\n",
      "Work Experience:\n",
      "- I am currently a student and do not have any formal work experience. However, I have gained practical skills through academic projects and internships.\n",
      "\n",
      "Academic Challenges:\n",
      "The most challenging aspect of my studies so far has been balancing coursework with research. The fast-paced nature of data science and AI requires constant learning and adaptation, which can be overwhelming at times. However, I view this as an opportunity to grow and develop resilience.\n",
      "\n",
      "Question: What major or field of study did you pursue during your education?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "[HumanMessage(content='How old are you?', additional_kwargs={}, response_metadata={}), AIMessage(content='22', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is your highest level of education?', additional_kwargs={}, response_metadata={}), AIMessage(content='Master’s Degree', additional_kwargs={}, response_metadata={}), HumanMessage(content='What major or field of study did you pursue during your education?', additional_kwargs={}, response_metadata={}), AIMessage(content='data science and AI', additional_kwargs={}, response_metadata={})]\n",
      "Follow Up Input: How many years of work experience do you have?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Academic Challenges and Research Interests\n",
      "\n",
      "Work Experience:\n",
      "- I am currently a student and do not have any formal work experience. However, I have gained practical skills through academic projects and internships.\n",
      "\n",
      "Academic Challenges:\n",
      "The most challenging aspect of my studies so far has been balancing coursework with research. The fast-paced nature of data science and AI requires constant learning and adaptation, which can be overwhelming at times. However, I view this as an opportunity to grow and develop resilience.\n",
      "\n",
      "Academic Challenges and Research Interests\n",
      "\n",
      "Work Experience:\n",
      "- I am currently a student and do not have any formal work experience. However, I have gained practical skills through academic projects and internships.\n",
      "\n",
      "Academic Challenges:\n",
      "The most challenging aspect of my studies so far has been balancing coursework with research. The fast-paced nature of data science and AI requires constant learning and adaptation, which can be overwhelming at times. However, I view this as an opportunity to grow and develop resilience.\n",
      "\n",
      "Academic Challenges and Research Interests\n",
      "\n",
      "Work Experience:\n",
      "- I am currently a student and do not have any formal work experience. However, I have gained practical skills through academic projects and internships.\n",
      "\n",
      "Academic Challenges:\n",
      "The most challenging aspect of my studies so far has been balancing coursework with research. The fast-paced nature of data science and AI requires constant learning and adaptation, which can be overwhelming at times. However, I view this as an opportunity to grow and develop resilience.\n",
      "\n",
      "Academic Challenges and Research Interests\n",
      "\n",
      "Work Experience:\n",
      "- I am currently a student and do not have any formal work experience. However, I have gained practical skills through academic projects and internships.\n",
      "\n",
      "Academic Challenges:\n",
      "The most challenging aspect of my studies so far has been balancing coursework with research. The fast-paced nature of data science and AI requires constant learning and adaptation, which can be overwhelming at times. However, I view this as an opportunity to grow and develop resilience.\n",
      "\n",
      "Question: How many years of work experience do you have?\n",
      "Helpful Answer:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "[HumanMessage(content='What is your highest level of education?', additional_kwargs={}, response_metadata={}), AIMessage(content='Master’s Degree', additional_kwargs={}, response_metadata={}), HumanMessage(content='What major or field of study did you pursue during your education?', additional_kwargs={}, response_metadata={}), AIMessage(content='data science and AI', additional_kwargs={}, response_metadata={}), HumanMessage(content='How many years of work experience do you have?', additional_kwargs={}, response_metadata={}), AIMessage(content='I am currently a student and do not have any formal work experience', additional_kwargs={}, response_metadata={})]\n",
      "Follow Up Input: What type of work or industry have you been involved in?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Academic Challenges and Research Interests\n",
      "\n",
      "Work Experience:\n",
      "- I am currently a student and do not have any formal work experience. However, I have gained practical skills through academic projects and internships.\n",
      "\n",
      "Academic Challenges:\n",
      "The most challenging aspect of my studies so far has been balancing coursework with research. The fast-paced nature of data science and AI requires constant learning and adaptation, which can be overwhelming at times. However, I view this as an opportunity to grow and develop resilience.\n",
      "\n",
      "Academic Challenges and Research Interests\n",
      "\n",
      "Work Experience:\n",
      "- I am currently a student and do not have any formal work experience. However, I have gained practical skills through academic projects and internships.\n",
      "\n",
      "Academic Challenges:\n",
      "The most challenging aspect of my studies so far has been balancing coursework with research. The fast-paced nature of data science and AI requires constant learning and adaptation, which can be overwhelming at times. However, I view this as an opportunity to grow and develop resilience.\n",
      "\n",
      "Academic Challenges and Research Interests\n",
      "\n",
      "Work Experience:\n",
      "- I am currently a student and do not have any formal work experience. However, I have gained practical skills through academic projects and internships.\n",
      "\n",
      "Academic Challenges:\n",
      "The most challenging aspect of my studies so far has been balancing coursework with research. The fast-paced nature of data science and AI requires constant learning and adaptation, which can be overwhelming at times. However, I view this as an opportunity to grow and develop resilience.\n",
      "\n",
      "Academic Challenges and Research Interests\n",
      "\n",
      "Work Experience:\n",
      "- I am currently a student and do not have any formal work experience. However, I have gained practical skills through academic projects and internships.\n",
      "\n",
      "Academic Challenges:\n",
      "The most challenging aspect of my studies so far has been balancing coursework with research. The fast-paced nature of data science and AI requires constant learning and adaptation, which can be overwhelming at times. However, I view this as an opportunity to grow and develop resilience.\n",
      "\n",
      "Question: What type of work or industry have you been involved in?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "[HumanMessage(content='What major or field of study did you pursue during your education?', additional_kwargs={}, response_metadata={}), AIMessage(content='data science and AI', additional_kwargs={}, response_metadata={}), HumanMessage(content='How many years of work experience do you have?', additional_kwargs={}, response_metadata={}), AIMessage(content='I am currently a student and do not have any formal work experience', additional_kwargs={}, response_metadata={}), HumanMessage(content='What type of work or industry have you been involved in?', additional_kwargs={}, response_metadata={}), AIMessage(content='I am currently a student and do not have any formal work experience. However, I have gained practical skills through academic projects and internships.', additional_kwargs={}, response_metadata={})]\n",
      "Follow Up Input: Can you describe your current role or job responsibilities?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Academic Goals:\n",
      "- Publish at least two research papers in top-tier conferences (e.g., NeurIPS, ICML).\n",
      "- Collaborate with industry partners to apply my research in real-world scenarios.\n",
      "- Develop a strong foundation in AI ethics to ensure my work benefits society as a whole.\n",
      "\n",
      "Academic Goals:\n",
      "- Publish at least two research papers in top-tier conferences (e.g., NeurIPS, ICML).\n",
      "- Collaborate with industry partners to apply my research in real-world scenarios.\n",
      "- Develop a strong foundation in AI ethics to ensure my work benefits society as a whole.\n",
      "\n",
      "Academic Goals:\n",
      "- Publish at least two research papers in top-tier conferences (e.g., NeurIPS, ICML).\n",
      "- Collaborate with industry partners to apply my research in real-world scenarios.\n",
      "- Develop a strong foundation in AI ethics to ensure my work benefits society as a whole.\n",
      "\n",
      "Academic Goals:\n",
      "- Publish at least two research papers in top-tier conferences (e.g., NeurIPS, ICML).\n",
      "- Collaborate with industry partners to apply my research in real-world scenarios.\n",
      "- Develop a strong foundation in AI ethics to ensure my work benefits society as a whole.\n",
      "\n",
      "Question: Can you describe your current role or job responsibilities?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "[HumanMessage(content='How many years of work experience do you have?', additional_kwargs={}, response_metadata={}), AIMessage(content='I am currently a student and do not have any formal work experience', additional_kwargs={}, response_metadata={}), HumanMessage(content='What type of work or industry have you been involved in?', additional_kwargs={}, response_metadata={}), AIMessage(content='I am currently a student and do not have any formal work experience. However, I have gained practical skills through academic projects and internships.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Can you describe your current role or job responsibilities?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I don't know\", additional_kwargs={}, response_metadata={})]\n",
      "Follow Up Input: What are your core beliefs regarding the role of technology in shaping society?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Personal Beliefs and Cultural Perspectives\n",
      "\n",
      "Core Beliefs about Technology:\n",
      "I believe that technology has the power to transform societies by improving access to education, healthcare, and economic opportunities. However, it is crucial to ensure that technological advancements are inclusive and ethical, addressing the needs of all communities, especially marginalized ones.\n",
      "\n",
      "Personal Beliefs and Cultural Perspectives\n",
      "\n",
      "Core Beliefs about Technology:\n",
      "I believe that technology has the power to transform societies by improving access to education, healthcare, and economic opportunities. However, it is crucial to ensure that technological advancements are inclusive and ethical, addressing the needs of all communities, especially marginalized ones.\n",
      "\n",
      "Personal Beliefs and Cultural Perspectives\n",
      "\n",
      "Core Beliefs about Technology:\n",
      "I believe that technology has the power to transform societies by improving access to education, healthcare, and economic opportunities. However, it is crucial to ensure that technological advancements are inclusive and ethical, addressing the needs of all communities, especially marginalized ones.\n",
      "\n",
      "Personal Beliefs and Cultural Perspectives\n",
      "\n",
      "Core Beliefs about Technology:\n",
      "I believe that technology has the power to transform societies by improving access to education, healthcare, and economic opportunities. However, it is crucial to ensure that technological advancements are inclusive and ethical, addressing the needs of all communities, especially marginalized ones.\n",
      "\n",
      "Question: What are your core beliefs regarding the role of technology in shaping society?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "[HumanMessage(content='What type of work or industry have you been involved in?', additional_kwargs={}, response_metadata={}), AIMessage(content='I am currently a student and do not have any formal work experience. However, I have gained practical skills through academic projects and internships.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Can you describe your current role or job responsibilities?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I don't know\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What are your core beliefs regarding the role of technology in shaping society?', additional_kwargs={}, response_metadata={}), AIMessage(content='I believe that technology has the power to transform societies by improving access to education, healthcare, and economic opportunities. However, it is crucial to ensure that technological advancements are inclusive and ethical, addressing the needs of all communities, especially marginalized ones.', additional_kwargs={}, response_metadata={})]\n",
      "Follow Up Input: How do you think cultural values should influence technological advancements?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Cultural Values and Technology:\n",
      "Cultural values should play a significant role in shaping technological advancements. For example, in collectivist cultures, technology should prioritize community well-being over individual gains. Additionally, cultural sensitivity should be embedded in AI systems to avoid biases and ensure fairness.\n",
      "\n",
      "Views on Societal Impact:\n",
      "I am passionate about using technology to solve real-world problems, such as improving agricultural yields, enhancing healthcare access, and promoting education in underserved areas. I believe that technology should be a tool for empowerment and equality.\n",
      "\n",
      "Cultural Values and Technology:\n",
      "Cultural values should play a significant role in shaping technological advancements. For example, in collectivist cultures, technology should prioritize community well-being over individual gains. Additionally, cultural sensitivity should be embedded in AI systems to avoid biases and ensure fairness.\n",
      "\n",
      "Views on Societal Impact:\n",
      "I am passionate about using technology to solve real-world problems, such as improving agricultural yields, enhancing healthcare access, and promoting education in underserved areas. I believe that technology should be a tool for empowerment and equality.\n",
      "\n",
      "Cultural Values and Technology:\n",
      "Cultural values should play a significant role in shaping technological advancements. For example, in collectivist cultures, technology should prioritize community well-being over individual gains. Additionally, cultural sensitivity should be embedded in AI systems to avoid biases and ensure fairness.\n",
      "\n",
      "Views on Societal Impact:\n",
      "I am passionate about using technology to solve real-world problems, such as improving agricultural yields, enhancing healthcare access, and promoting education in underserved areas. I believe that technology should be a tool for empowerment and equality.\n",
      "\n",
      "Cultural Values and Technology:\n",
      "Cultural values should play a significant role in shaping technological advancements. For example, in collectivist cultures, technology should prioritize community well-being over individual gains. Additionally, cultural sensitivity should be embedded in AI systems to avoid biases and ensure fairness.\n",
      "\n",
      "Views on Societal Impact:\n",
      "I am passionate about using technology to solve real-world problems, such as improving agricultural yields, enhancing healthcare access, and promoting education in underserved areas. I believe that technology should be a tool for empowerment and equality.\n",
      "\n",
      "Question: What do you think should influence the role of cultural values in technological advancements?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "[HumanMessage(content='Can you describe your current role or job responsibilities?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I don't know\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What are your core beliefs regarding the role of technology in shaping society?', additional_kwargs={}, response_metadata={}), AIMessage(content='I believe that technology has the power to transform societies by improving access to education, healthcare, and economic opportunities. However, it is crucial to ensure that technological advancements are inclusive and ethical, addressing the needs of all communities, especially marginalized ones.', additional_kwargs={}, response_metadata={}), HumanMessage(content='How do you think cultural values should influence technological advancements?', additional_kwargs={}, response_metadata={}), AIMessage(content='collectivist cultures', additional_kwargs={}, response_metadata={})]\n",
      "Follow Up Input: As a master’s student, what is the most challenging aspect of your studies so far?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Academic Challenges and Research Interests\n",
      "\n",
      "Work Experience:\n",
      "- I am currently a student and do not have any formal work experience. However, I have gained practical skills through academic projects and internships.\n",
      "\n",
      "Academic Challenges:\n",
      "The most challenging aspect of my studies so far has been balancing coursework with research. The fast-paced nature of data science and AI requires constant learning and adaptation, which can be overwhelming at times. However, I view this as an opportunity to grow and develop resilience.\n",
      "\n",
      "Academic Challenges and Research Interests\n",
      "\n",
      "Work Experience:\n",
      "- I am currently a student and do not have any formal work experience. However, I have gained practical skills through academic projects and internships.\n",
      "\n",
      "Academic Challenges:\n",
      "The most challenging aspect of my studies so far has been balancing coursework with research. The fast-paced nature of data science and AI requires constant learning and adaptation, which can be overwhelming at times. However, I view this as an opportunity to grow and develop resilience.\n",
      "\n",
      "Academic Challenges and Research Interests\n",
      "\n",
      "Work Experience:\n",
      "- I am currently a student and do not have any formal work experience. However, I have gained practical skills through academic projects and internships.\n",
      "\n",
      "Academic Challenges:\n",
      "The most challenging aspect of my studies so far has been balancing coursework with research. The fast-paced nature of data science and AI requires constant learning and adaptation, which can be overwhelming at times. However, I view this as an opportunity to grow and develop resilience.\n",
      "\n",
      "Academic Challenges and Research Interests\n",
      "\n",
      "Work Experience:\n",
      "- I am currently a student and do not have any formal work experience. However, I have gained practical skills through academic projects and internships.\n",
      "\n",
      "Academic Challenges:\n",
      "The most challenging aspect of my studies so far has been balancing coursework with research. The fast-paced nature of data science and AI requires constant learning and adaptation, which can be overwhelming at times. However, I view this as an opportunity to grow and develop resilience.\n",
      "\n",
      "Question: What is the most challenging aspect of your studies so far?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "[HumanMessage(content='What are your core beliefs regarding the role of technology in shaping society?', additional_kwargs={}, response_metadata={}), AIMessage(content='I believe that technology has the power to transform societies by improving access to education, healthcare, and economic opportunities. However, it is crucial to ensure that technological advancements are inclusive and ethical, addressing the needs of all communities, especially marginalized ones.', additional_kwargs={}, response_metadata={}), HumanMessage(content='How do you think cultural values should influence technological advancements?', additional_kwargs={}, response_metadata={}), AIMessage(content='collectivist cultures', additional_kwargs={}, response_metadata={}), HumanMessage(content='As a master’s student, what is the most challenging aspect of your studies so far?', additional_kwargs={}, response_metadata={}), AIMessage(content='balancing coursework with research', additional_kwargs={}, response_metadata={})]\n",
      "Follow Up Input: What specific research interests or academic goals do you hope to achieve during your time as a master’s student?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Academic Challenges and Research Interests\n",
      "\n",
      "Work Experience:\n",
      "- I am currently a student and do not have any formal work experience. However, I have gained practical skills through academic projects and internships.\n",
      "\n",
      "Academic Challenges:\n",
      "The most challenging aspect of my studies so far has been balancing coursework with research. The fast-paced nature of data science and AI requires constant learning and adaptation, which can be overwhelming at times. However, I view this as an opportunity to grow and develop resilience.\n",
      "\n",
      "Academic Challenges and Research Interests\n",
      "\n",
      "Work Experience:\n",
      "- I am currently a student and do not have any formal work experience. However, I have gained practical skills through academic projects and internships.\n",
      "\n",
      "Academic Challenges:\n",
      "The most challenging aspect of my studies so far has been balancing coursework with research. The fast-paced nature of data science and AI requires constant learning and adaptation, which can be overwhelming at times. However, I view this as an opportunity to grow and develop resilience.\n",
      "\n",
      "Academic Challenges and Research Interests\n",
      "\n",
      "Work Experience:\n",
      "- I am currently a student and do not have any formal work experience. However, I have gained practical skills through academic projects and internships.\n",
      "\n",
      "Academic Challenges:\n",
      "The most challenging aspect of my studies so far has been balancing coursework with research. The fast-paced nature of data science and AI requires constant learning and adaptation, which can be overwhelming at times. However, I view this as an opportunity to grow and develop resilience.\n",
      "\n",
      "Academic Challenges and Research Interests\n",
      "\n",
      "Work Experience:\n",
      "- I am currently a student and do not have any formal work experience. However, I have gained practical skills through academic projects and internships.\n",
      "\n",
      "Academic Challenges:\n",
      "The most challenging aspect of my studies so far has been balancing coursework with research. The fast-paced nature of data science and AI requires constant learning and adaptation, which can be overwhelming at times. However, I view this as an opportunity to grow and develop resilience.\n",
      "\n",
      "Question: What specific research interests or academic goals do you hope to achieve during your time as a master’s student?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Question-answer pairs saved to question_answer_pairs.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# Step 1: Define the questions\n",
    "questions = [\n",
    "    \"How old are you?\",\n",
    "    \"What is your highest level of education?\",\n",
    "    \"What major or field of study did you pursue during your education?\",\n",
    "    \"How many years of work experience do you have?\",\n",
    "    \"What type of work or industry have you been involved in?\",\n",
    "    \"Can you describe your current role or job responsibilities?\",\n",
    "    \"What are your core beliefs regarding the role of technology in shaping society?\",\n",
    "    \"How do you think cultural values should influence technological advancements?\",\n",
    "    \"As a master’s student, what is the most challenging aspect of your studies so far?\",\n",
    "    \"What specific research interests or academic goals do you hope to achieve during your time as a master’s student?\"\n",
    "]\n",
    "\n",
    "# Step 2: Initialize an empty list for question-answer pairs\n",
    "qa_pairs = []\n",
    "\n",
    "# Step 3: Generate answers using the chatbot\n",
    "for question in questions:\n",
    "    response = chain({\"question\": question})\n",
    "    answer = response[\"answer\"]\n",
    "    qa_pairs.append({\n",
    "        \"question\": question,\n",
    "        \"answer\": answer\n",
    "    })\n",
    "\n",
    "# Step 4: Convert to JSON and save to a file\n",
    "json_output = json.dumps(qa_pairs, indent=2)\n",
    "with open(\"question_answer_pairs.json\", \"w\") as f:\n",
    "    f.write(json_output)\n",
    "\n",
    "print(\"Question-answer pairs saved to question_answer_pairs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37a2ea4-8e44-4f3a-bae1-49a85ab97dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
